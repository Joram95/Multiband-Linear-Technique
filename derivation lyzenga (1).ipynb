{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import os\n",
    "import csv\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35782bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calc relitive depth\n",
    "\n",
    "# Calibration\n",
    "def calculate_depth(sum_logbands, slope, intercept):\n",
    "    \n",
    "    # Calibration of Sat derived depth\n",
    "    depth = (slope_cal * sum_logbands) + intercept_cal\n",
    "    return depth\n",
    "\n",
    "# Function to load residuals from a CSV file\n",
    "def load_residuals_from_csv(filename):\n",
    "    residuals = []\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            # Skip header\n",
    "            next(csv_reader)\n",
    "            # Read data\n",
    "            for row in csv_reader:\n",
    "                residuals.append([float(item) for item in row])\n",
    "    return residuals\n",
    "\n",
    "# save and re-Save the residuals at each validation observatio\n",
    "def save_to_residuals(residual_val, depth_cleaned, Lidar_val_cleaned, Ben_val_cleaned, spatial_res, spectral_res, N):\n",
    "    # Get the next ID by adding 1 to the ID of the last entry in the list, if any\n",
    "    next_id = Residuals[-1][0] + 1 if Residuals else 1\n",
    "    # Iterate over each observation point and append its information to the data array\n",
    "    for i in range(len(residual_val)):\n",
    "        Residuals.append([next_id + i, residual_val[i], depth_cleaned[i], Lidar_val_cleaned[i], Ben_val_cleaned[i], spatial_res, spectral_res, N])\n",
    "\n",
    "def save_residuals_to_csv(filename, residuals):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        csv_writer.writerow([\"ID\", \"Residual\", \"Depth\", \"LiDAR_value\", \"Benthos_value\", \"Spatial_resolution\", \"Spectral_resolution\"])\n",
    "        # Write data\n",
    "        csv_writer.writerows(residuals)\n",
    "\n",
    "# Save the metrics of derivation quality\n",
    "def save_to_results(derivation_technique, satellite_id, bands, slope_cal, intercept_cal, r_squared_val, rmse_val, mean_residual, mean_residual_sand, mean_residual_non_sand):\n",
    "    # Generate a new ID number by adding 1 to the length of the data array\n",
    "    new_id = len(results) + 1\n",
    "    # Append the key information to the data array\n",
    "    results.append([new_id, derivation_technique, satellite_id, bands, slope_cal, intercept_cal, r_squared_val, rmse_val, mean_residual, mean_residual_sand, mean_residual_non_sand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory where the Raw folder is located\n",
    "root_dir = 'Raw/'\n",
    "\n",
    "# Define file paths for satellite images\n",
    "sat_img_dir = os.path.join(root_dir, 'sat_img/Pre_Noise_removal')\n",
    "PN_path = os.path.join(sat_img_dir, 'PN_image.tif')\n",
    "PSSD_path = os.path.join(sat_img_dir, 'PSSD_image.tif')\n",
    "S2_path = os.path.join(sat_img_dir, 'S2_image.tif')\n",
    "\n",
    "# Define file paths for benthic rasters\n",
    "benthos_dir = os.path.join(root_dir, 'benthos')\n",
    "ben120path = os.path.join(benthos_dir, 'ben120.tif')\n",
    "ben300path = os.path.join(benthos_dir, 'ben300.tif')\n",
    "ben1000path = os.path.join(benthos_dir, 'ben1000.tif')\n",
    "\n",
    "# Define file paths for bathy-LiDAR cal val rasters\n",
    "bathy_LiDAR_dir = os.path.join(root_dir, 'bathy_LiDAR/Tidally_Corrected_with_DEWprofile_200004')\n",
    "bathy120_cal_path = os.path.join(bathy_LiDAR_dir, 'bathy120_cal.tif')\n",
    "bathy300_cal_path = os.path.join(bathy_LiDAR_dir, 'bathy300_cal.tif')\n",
    "bathy1000_cal_path = os.path.join(bathy_LiDAR_dir, 'bathy1000_cal.tif')\n",
    "bathy120_val_path = os.path.join(bathy_LiDAR_dir, 'bathy120_val.tif')\n",
    "bathy300_val_path = os.path.join(bathy_LiDAR_dir, 'bathy300_val.tif')\n",
    "bathy1000_val_path = os.path.join(bathy_LiDAR_dir, 'bathy1000_val.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sat imagery\n",
    "\n",
    "# Load PN raster data and set 0 values to NoData (NaN)\n",
    "with rasterio.open(PN_path) as src_PN:\n",
    "    PN = src_PN.read().astype(float)  # Read all bands and convert to float\n",
    "    PN_crs = src_PN.crs\n",
    "    PN[PN > 10000] = np.nan\n",
    "\n",
    "# Load PSSD raster data and set 0 values to NoData (NaN)\n",
    "with rasterio.open(PSSD_path) as src_PSSD:\n",
    "    PSSD = src_PSSD.read().astype(float)  # Read all bands and convert to float\n",
    "    PSSD_crs = src_PSSD.crs\n",
    "    PSSD[PSSD > 10000] = np.nan\n",
    "\n",
    "# Load S2 raster data and set 0 values to NoData (NaN)\n",
    "with rasterio.open(S2_path) as src_S2:\n",
    "    S2 = src_S2.read().astype(float)  # Read all bands and convert to float\n",
    "    S2_crs = src_S2.crs\n",
    "    S2[S2 > 10000] = np.nan\n",
    "    \n",
    "# Check CRS\n",
    "print(\"CRS for PN:\", PN_crs)\n",
    "print(\"CRS for PSSD:\", PSSD_crs)\n",
    "print(\"CRS for S2:\", S2_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be03fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename those bands\n",
    "\n",
    "S2b = S2[2]\n",
    "S2g = S2[1]\n",
    "S2r = S2[0]\n",
    "\n",
    "PSSDdb = PSSD[5]\n",
    "PSSDb = PSSD[4]\n",
    "PSSDg1 = PSSD[3]\n",
    "PSSDg2 = PSSD[2]\n",
    "PSSDy = PSSD[1]\n",
    "PSSDr = PSSD[0] \n",
    "\n",
    "PNdb = PN[3]\n",
    "PNb = PN[2]\n",
    "PNg = PN[1]\n",
    "PNr = PN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data as a sanity check,\n",
    "\n",
    "#visualise the bands\n",
    "plt.imshow(PSSDg2, cmap='viridis', vmin=200, vmax=750)\n",
    "plt.colorbar(label='Pixel Value')\n",
    "plt.show()\n",
    "\n",
    "#histogram to settle on min and max stretch values\n",
    "plt.hist(PSSDg2.flatten(), bins =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the benthic rasters and set 15 values to NoData (NaN)\n",
    "with rasterio.open(ben120path) as src_ben120:\n",
    "    ben120 = src_ben120.read().astype(float)\n",
    "    ben120_crs = src_ben120.crs\n",
    "    ben120[ben120 == 15] = np.nan\n",
    "    \n",
    "with rasterio.open(ben300path) as src_ben300:\n",
    "    ben300 = src_ben300.read().astype(float)\n",
    "    ben300_crs = src_ben300.crs\n",
    "    ben300[ben300 == 15] = np.nan\n",
    "        \n",
    "with rasterio.open(ben1000path) as src_ben1000:\n",
    "    ben1000 = src_ben1000.read().astype(float) \n",
    "    ben1000_crs = src_ben1000.crs\n",
    "    ben1000[ben1000 == 15] = np.nan\n",
    "        \n",
    "# Check CRS\n",
    "print(\"CRS for ben120:\", ben120_crs)\n",
    "print(\"CRS for ben300:\", ben300_crs)\n",
    "print(\"CRS for ben1000:\", ben1000_crs)\n",
    "\n",
    "# Plot benthic rasters\n",
    "plt.imshow(ben120[0], cmap='viridis')\n",
    "plt.colorbar(label='Pixel Value')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(ben120.flatten(), bins =50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bathy-LiDAR calibration rasters\n",
    "with rasterio.open(bathy120_cal_path) as src_bathy120_cal:\n",
    "    bathy120_cal = src_bathy120_cal.read().astype(float)\n",
    "    bathy120_cal_crs = src_bathy120_cal.crs\n",
    "    bathy120_cal[(bathy120_cal == -9999) | (bathy120_cal < 0.5) | (bathy120_cal > 5)] = np.nan\n",
    "        \n",
    "with rasterio.open(bathy300_cal_path) as src_bathy300_cal:\n",
    "    bathy300_cal = src_bathy300_cal.read().astype(float)\n",
    "    bathy300_cal_crs = src_bathy300_cal.crs\n",
    "    bathy300_cal[(bathy300_cal == -9999) | (bathy300_cal < 0.5) | (bathy300_cal > 5)] = np.nan\n",
    "\n",
    "with rasterio.open(bathy1000_cal_path) as src_bathy1000_cal:\n",
    "    bathy1000_cal = src_bathy1000_cal.read().astype(float)\n",
    "    bathy1000_cal_crs = src_bathy1000_cal.crs\n",
    "    bathy1000_cal[(bathy1000_cal == -9999) | (bathy1000_cal < 0.5) | (bathy1000_cal > 5)] = np.nan\n",
    "\n",
    "# Similarly, load validation data\n",
    "with rasterio.open(bathy120_val_path) as src_bathy120_val:\n",
    "    bathy120_val = src_bathy120_val.read().astype(float)\n",
    "    bathy120_val_crs = src_bathy120_val.crs\n",
    "    bathy120_val[(bathy120_val == -9999) | (bathy120_val < 0.5) | (bathy120_val > 5)] = np.nan\n",
    "\n",
    "with rasterio.open(bathy300_val_path) as src_bathy300_val:\n",
    "    bathy300_val = src_bathy300_val.read().astype(float)\n",
    "    bathy300_val_crs = src_bathy300_val.crs\n",
    "    bathy300_val[(bathy300_val == -9999) | (bathy300_val < 0.5) | (bathy300_val > 5)] = np.nan\n",
    "\n",
    "with rasterio.open(bathy1000_val_path) as src_bathy1000_val:\n",
    "    bathy1000_val = src_bathy1000_val.read().astype(float)\n",
    "    bathy1000_val_crs = src_bathy1000_val.crs\n",
    "    bathy1000_val[(bathy1000_val == -9999) | (bathy1000_val < 0.5) | (bathy1000_val > 5)] = np.nan\n",
    "\n",
    "# Plot the histogram for bathy1000_val\n",
    "plt.hist(bathy300_val.flatten(), bins=50, alpha=0.5, label='Validation Data')\n",
    "\n",
    "# Plot the histogram for bathy1000_cal\n",
    "plt.hist(bathy300_cal.flatten(), bins=50, alpha=0.5, label='Calibration Data')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Pixel Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Check CRS\n",
    "print(\"CRS for bathy120_cal:\", bathy120_cal_crs)\n",
    "print(\"CRS for bathy300_cal:\", bathy300_cal_crs)\n",
    "print(\"CRS for bathy1000_cal:\", bathy1000_cal_crs)\n",
    "print(\"CRS for bathy120_val:\", bathy120_val_crs)\n",
    "print(\"CRS for bathy300_val:\", bathy300_val_crs)\n",
    "print(\"CRS for bathy1000_val:\", bathy1000_val_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a new dataset\n",
    "#dont do this if you already have one!!!!\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2da1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE ME!!!\n",
    "# create a variables for the derivation identification\n",
    "Derivation_Technique = 'Multiband Linear Method'\n",
    "Satellite_ID = 'PlanetScope SuperDove'\n",
    "Bands = 'B, G-alt, G'\n",
    "spatial_res = 3\n",
    "N = 3 #Number of Bands\n",
    "\n",
    "# Create a title using the variables\n",
    "title = f\"{Derivation_Technique} on {Satellite_ID} using {Bands} Bands\"\n",
    "\n",
    "# create a variables for the bands used\n",
    "B1 = PSSDg1\n",
    "B2 = PSSDg2\n",
    "B3 = PSSDy\n",
    "#B4 = PSSDr\n",
    "#B5 = PSSDb\n",
    "#B6 = PSSDr\n",
    "\n",
    "# For the Benthos\n",
    "Ben = ben300[0]\n",
    "\n",
    "# And the LiDAR\n",
    "Lidar_cal = bathy300_cal[0]\n",
    "Lidar_val = bathy300_val[0]\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f623ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE ME!!!!\n",
    "# calulate sum_logbands. Take the natural log of the band values and sum them together\n",
    "sum_logbands = (np.log(B1)) + (np.log(B2)) + (np.log(B3))\n",
    "\n",
    "# Plot histogram just to analyse sum_logbands now that the data is flattened\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(sum_logbands.flatten(), bins=100, color='blue', alpha=0.7)\n",
    "plt.xlim(16, 24)\n",
    "plt.title('Histogram of sum_logbands')\n",
    "plt.xlabel('sum_logbands')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the sum_logbands as an image\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(sum_logbands, cmap='viridis', vmin=17, vmax=20.5)\n",
    "plt.colorbar(label='sum_logbands')\n",
    "plt.title('sum_logbands')\n",
    "plt.xlabel('Pixel X')\n",
    "plt.ylabel('Pixel Y')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e28bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update MEEE!!!!\n",
    "\n",
    "#calculate spectral res of derivation\n",
    "#Spectral Resolution  spectral_res = 10 Log10 [10*N / (spec_range * Avbw )] \n",
    "#where  N = no. of bands, Avbw = average band width (nm), spec_range = spectral range of all bands (nm)\n",
    "\n",
    "#first bandwidth (bw)\n",
    "PSSDdb_bw = 21 \n",
    "PSSDb_bw = 50\n",
    "PSSDg1_bw = 36\n",
    "PSSDg2_bw = 36\n",
    "PSSDy_bw = 20\n",
    "PSSDr_bw = 30\n",
    "PNdb_bw = 50\n",
    "PNb_bw = 70\n",
    "PNg_bw = 60\n",
    "PNr_bw = 70\n",
    "S2b_bw = 66\n",
    "S2g_bw = 36\n",
    "S2r_bw = 31\n",
    "\n",
    "#now band mid-points to calc spec_rang\n",
    "PSSDdb_mp = 441.5\n",
    "PSSDb_mp = 490\n",
    "PSSDg1_mp = 531\n",
    "PSSDg2_mp = 565\n",
    "PSSDy_mp = 610\n",
    "PSSDr_mp = 665\n",
    "PNdb_mp = 425\n",
    "PNb_mp = 485\n",
    "PNg_mp = 560\n",
    "PNr_mp = 655\n",
    "S2b_mp = 492\n",
    "S2g_mp = 559\n",
    "S2r_mp = 664.5\n",
    "\n",
    "#Update Me!!!\n",
    "#Calc Spec_Range \n",
    "#spec_range = S2r_bw # if only 1 band\n",
    "spec_range = (PSSDy_13mp + (PSSDy_bw / 2)) - (PSSDg1_mp - (PSSDg1_bw / 2)) #hightest wavelength band first, lowest band last\n",
    "print(\"spec_range =\", spec_range)\n",
    "\n",
    "#Update Me!!!\n",
    "#Calc AvBw\n",
    "#AvBw = S2r_bw # if 1 band only\n",
    "AvBw = (PSSDy_bw + PSSDg1_bw + PSSDg2_bw)/N # add all bands\n",
    "print(\"average bandwidth =\", AvBw)\n",
    "                                 \n",
    "#Now calc the spectral res of derivation\n",
    "spectral_res = 10 * math.log10((10 * N) / (spec_range * AvBw))\n",
    "print(\"spectral resolution =\", spectral_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb97842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of each dataset to ensure we are comparing the same geographic space between all 3 rasters\n",
    "sum_logbands_shape = sum_logbands.shape\n",
    "Ben_shape = Ben.shape\n",
    "Lidar_cal_shape = Lidar_cal.shape\n",
    "\n",
    "# Print the number of columns and rows in each dataset\n",
    "print(\"Shape of sum_logbands:\", sum_logbands_shape)\n",
    "print(\"Shape of Ben:\", Ben_shape)\n",
    "print(\"Shape of Lidar_cal:\", Lidar_cal_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the relative depth against the real depth\n",
    "# To do so we need to remove pixels in both array's where either raster has nodata.  \n",
    "# Find valid pixels where none of the arrays have NaN values\n",
    "valid_cal_pixels = np.where(~np.isnan(sum_logbands) & ~np.isnan(Ben) & ~np.isnan(Lidar_cal))\n",
    "\n",
    "# Extract valid pixel values from rasters\n",
    "Ben_cal_cleaned = Ben[valid_cal_pixels]\n",
    "Lidar_cal_cleaned = Lidar_cal[valid_cal_pixels]\n",
    "sum_logbands_cleaned = sum_logbands[valid_cal_pixels]\n",
    "\n",
    "# Print the length of the cleaned arrays\n",
    "print(\"Length of sum_logbands_cleaned:\", len(sum_logbands_cleaned))\n",
    "print(\"Length of Ben_cal_cleaned:\", len(Ben_cal_cleaned))\n",
    "print(\"Length of Lidar_cal_cleaned\", len(Lidar_cal_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9728909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter plot\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(sum_logbands_cleaned, Lidar_cal_cleaned, s=10, c='b', alpha=0.15)\n",
    "plt.xlim(np.min(sum_logbands_cleaned)-0.001, np.max(sum_logbands_cleaned)+0.001)  # Set x-axis bounds\n",
    "plt.ylim(-0.5,8)  # Set y-axis bounds\n",
    "\n",
    "# Set major and minor gridlines\n",
    "plt.grid(True, which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "plt.grid(True, which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.gca().yaxis.set_major_locator(MultipleLocator(1.0)) # Set major and minor tick locators\n",
    "plt.gca().yaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Relative Depth')\n",
    "plt.ylabel('Depth Observations at Time of Image Capture (m)')\n",
    "plt.title(title)\n",
    "\n",
    "# Fit a linear regression line\n",
    "slope_cal, intercept_cal = np.polyfit(sum_logbands_cleaned, Lidar_cal_cleaned, 1)\n",
    "predicted = slope_cal * np.array(sum_logbands_cleaned) + intercept_cal\n",
    "residuals = Lidar_cal_cleaned - predicted\n",
    "ss_res = np.sum(residuals**2)\n",
    "ss_tot = np.sum((Lidar_cal_cleaned - np.mean(Lidar_cal_cleaned))**2)\n",
    "r_squared_cal = 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Plot the line\n",
    "plt.plot(sum_logbands_cleaned, slope_cal * sum_logbands_cleaned + intercept_cal, color='red', alpha=1, linewidth=2, linestyle='solid')\n",
    "\n",
    "# Add the equation of the line with a semi-transparent box\n",
    "equation_text = f'y = {slope_cal:.4f}x + {intercept_cal:.4f}\\n$R^2$ = {r_squared_cal:.2f}'\n",
    "plt.text(0.95, 0.95, equation_text, horizontalalignment='right', verticalalignment='top', transform=plt.gca().transAxes, fontsize=12, color='black', bbox=dict(facecolor='white', alpha=0.85, edgecolor='grey'))\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print the important values\n",
    "print(\"r2_cal =\",r_squared_cal)\n",
    "print(\"slope_cal\",slope_cal)\n",
    "print(\"y-intercept_cal\",intercept_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the prior function to calibrate the data\n",
    "\n",
    "depth = calculate_depth(sum_logbands, slope_cal, intercept_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot depth as an image\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(depth, cmap='viridis', vmin=0, vmax=6)\n",
    "plt.colorbar(label='Depth (m)')\n",
    "plt.title('Satellite Derived Depth')\n",
    "plt.xlabel('Pixel X')\n",
    "plt.ylabel('Pixel Y')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfe12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "# Define the output file path\n",
    "depth_output_path = 'depth.tif'\n",
    "\n",
    "# Get metadata from one of the input rasters (assuming all have the same metadata)\n",
    "metadata = src_bathy120_val.meta\n",
    "\n",
    "# Update metadata for the depth raster\n",
    "metadata.update({\n",
    "    'driver': 'GTiff',  # Specify the driver\n",
    "    'count': 1,  # Number of bands in the output raster\n",
    "    'dtype': rasterio.float32,  # Data type of the output raster\n",
    "    'nodata': np.nan,  # NoData value\n",
    "})\n",
    "\n",
    "# Create an Affine transformation for the output raster\n",
    "transform = Affine(src_bathy120_val.transform.a, src_bathy120_val.transform.b, src_bathy120_val.transform.c,\n",
    "                   src_bathy120_val.transform.d, src_bathy120_val.transform.e, src_bathy120_val.transform.f)\n",
    "\n",
    "# Write the depth raster to a GeoTIFF file\n",
    "with rasterio.open(depth_output_path, 'w', **metadata) as dst:\n",
    "    dst.write(depth.astype(rasterio.float32), 1)  # Write the depth array to the output raster\n",
    "    dst.transform = transform  # Set the transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now validate\n",
    "# Get the shape of each dataset to ensure we are comparing the same geographic space between all 3 rasters\n",
    "depth_shape = depth.shape\n",
    "Ben_shape = Ben.shape\n",
    "Lidar_val_shape = Lidar_val.shape\n",
    "\n",
    "# Print the number of columns and rows in each dataset\n",
    "print(\"Shape of depth:\", depth_shape)\n",
    "print(\"Shape of Ben:\", Ben_shape)\n",
    "print(\"Shape of Lidar_val:\", Lidar_val_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e133cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the relative depth against the real depth\n",
    "# To do so we need to remove pixels in both array's where either raster has nodata.  \n",
    "# Find valid pixels where none of the arrays have NaN values\n",
    "valid_val_pixels = np.where(~np.isnan(depth) & ~np.isnan(Ben) & ~np.isnan(Lidar_val))\n",
    "\n",
    "# Extract valid pixel values from rasters\n",
    "Ben_val_cleaned = Ben[valid_val_pixels]\n",
    "Lidar_val_cleaned = Lidar_val[valid_val_pixels]\n",
    "depth_cleaned = depth[valid_val_pixels]\n",
    "\n",
    "# Print the length of the cleaned arrays\n",
    "print(\"Length of depth_cleaned:\", len(depth_cleaned))\n",
    "print(\"Length of Ben_val_cleaned:\", len(Ben_val_cleaned))\n",
    "print(\"Length of Lidar_val_cleaned\", len(Lidar_val_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a validation scatter plot\n",
    "\n",
    "# Define the output directory to save off to\n",
    "output_directory = 'scatter_plots/'\n",
    "\n",
    "# Plot scatter plot\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Scatter plot for non-sand (benthic_data == 1)\n",
    "plt.scatter(depth_cleaned[Ben_val_cleaned == 1], Lidar_val_cleaned[Ben_val_cleaned == 1], s=10, c='darkgreen', alpha=0.35, label='Non-sand')\n",
    "# Scatter plot for sand (benthic_data == 2)\n",
    "plt.scatter(depth_cleaned[Ben_val_cleaned == 2], Lidar_val_cleaned[Ben_val_cleaned == 2], s=10, c='orange', alpha=0.35, label='Sand')\n",
    "\n",
    "plt.xlim(0, 8)  # Set x-axis bounds\n",
    "plt.ylim(0, 8)  # Set y-axis bounds\n",
    "\n",
    "# Set major and minor gridlines\n",
    "plt.grid(True, which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "plt.grid(True, which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.gca().yaxis.set_major_locator(MultipleLocator(1.0)) # Set major and minor tick locators\n",
    "plt.gca().yaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Satellite Derived Depth (m)')\n",
    "plt.ylabel('Depth Observations at Time of Image Capture (m)')\n",
    "plt.title(title)\n",
    "\n",
    "# Fit a linear regression line\n",
    "slope_val, intercept_val = np.polyfit(depth_cleaned, Lidar_val_cleaned, 1)\n",
    "predicted = slope_val * np.array(depth_cleaned) + intercept_val\n",
    "residuals = Lidar_val_cleaned - predicted\n",
    "ss_res = np.sum(residuals**2)\n",
    "ss_tot = np.sum((Lidar_val_cleaned - np.mean(Lidar_val_cleaned))**2)\n",
    "r_squared_val = 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Plot the line\n",
    "plt.plot(depth_cleaned, slope_val * depth_cleaned + intercept_val, color='black', alpha=1, linewidth=1.5, linestyle='solid')\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_val = np.sqrt(np.mean((Lidar_val_cleaned - predicted)**2))\n",
    "\n",
    "# Add the equation of the line with a semi-transparent box\n",
    "equation_text = f'y = {slope_val:.3f}x + {intercept_val:.3f}\\n$R^2$ = {r_squared_val:.2f}\\nRMSE = {rmse_val:.3f}'\n",
    "plt.text(0.025, 0.97, equation_text, horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes, fontsize=12, color='black', bbox=dict(facecolor='white', alpha=0.85, edgecolor='grey'))\n",
    "\n",
    "# Show legend\n",
    "#plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(output_directory, f\"{title}.png\"))\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print the important values\n",
    "print(\"r2_val =\", r_squared_val)\n",
    "print(\"slope_val =\", slope_val)\n",
    "print(\"y-intercept_val =\", intercept_val)\n",
    "print(\"RMSE =\", rmse_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d17ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now  from the observation save each validation observation as well as critical data\n",
    "# Calculate residuals\n",
    "residual_val = depth_cleaned - Lidar_val_cleaned\n",
    "\n",
    "# Separate residuals based on benthic classes\n",
    "residual_non_sand = [residual_val[i] for i in range(len(residual_val)) if Ben_val_cleaned[i] == 1]\n",
    "residual_sand = [residual_val[i] for i in range(len(residual_val)) if Ben_val_cleaned[i] == 2]\n",
    "\n",
    "# Calculate mean residual error for each class\n",
    "mean_residual = np.mean(residual_val)\n",
    "mean_residual_non_sand = np.mean(residual_non_sand)\n",
    "mean_residual_sand = np.mean(residual_sand)\n",
    "\n",
    "# Print or save the mean residual errors for each class\n",
    "print(\"Mean residual error:\", mean_residual)\n",
    "print(\"Mean residual error for non-sand class:\", mean_residual_non_sand)\n",
    "print(\"Mean residual error for sand class:\", mean_residual_sand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save residuals to a CSV file\n",
    "# Load previous residuals if they exist\n",
    "residuals_filename = 'residuals.csv'\n",
    "Residuals = load_residuals_from_csv(residuals_filename)\n",
    "\n",
    "# Call the function to save results\n",
    "save_to_residuals(residual_val, depth_cleaned, Lidar_val_cleaned, Ben_val_cleaned, spatial_res, spectral_res, N)\n",
    "\n",
    "# Display the results array\n",
    "print(\"Residuals:\")\n",
    "for entry in Residuals:\n",
    "    print(entry)\n",
    "\n",
    "# Export results to a CSV file\n",
    "save_residuals_to_csv(residuals_filename, Residuals)\n",
    "\n",
    "print(\"Residuals exported to\", residuals_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcf21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to save overall result metrics\n",
    "save_to_results(Derivation_Technique, Satellite_ID, Bands, slope_cal, intercept_cal, r_squared_val, rmse_val, mean_residual, mean_residual_sand, mean_residual_non_sand)\n",
    "\n",
    "# Display the results array\n",
    "print(\"Results:\")\n",
    "for entry in results:\n",
    "    print(entry)\n",
    "    \n",
    "# Export results to a CSV file\n",
    "with open('results.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write header\n",
    "    csv_writer.writerow([\"ID\", \"Derivation_Technique\", \"Satellite_ID\", \"Bands\", \"Slope_cal\", \"Intercept_cal\", \"R^2_val\", \"RMSE_val, mean_residual, mean_residual_sand, mean_residual_non_sand\"])\n",
    "    # Write data\n",
    "    csv_writer.writerows(results)\n",
    "\n",
    "print(\"Results exported to results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
